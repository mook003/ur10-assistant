#!/usr/bin/env python3
import rclpy
from rclpy.node import Node
import json
import time
import os
import math
import queue
import re
import sys
from difflib import SequenceMatcher

import sounddevice as sd
import vosk
#import URBasic
#import URBasic.robotModel
#import URBasic.urScriptExt
from ament_index_python.packages import get_package_share_directory

class VoiceController(Node):
    """–û—Å–Ω–æ–≤–Ω–æ–π —É–∑–µ–ª ROS2 –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–æ–±–æ—Ç–æ–º."""
    
    # –°–ª–æ–≤–∞—Ä—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
    TOOLS_DICT = {
        '–ø–æ—Å–º–æ—Ç—Ä–∏': ['–ø–æ—Å–º–æ—Ç—Ä–∏', '–∏–∑—É—á–∏', '–æ—Å–º–æ—Ç—Ä–∏', '–≤–∑–≥–ª—è–Ω–≥–∏'],
        '—Å–æ–±–∞—á–∫–∞': ['—Å–æ–±–∞–∫–∞', '—Å–æ–±–∞–∫—É', '—Å–æ–±–∞—á–∫—É'],
        '–Ω–∞–∑–∞–¥': ['–≤–µ—Ä–Ω–∏—Å—å', '–Ω–∞—á–∞–ª–æ', '–Ω–∞–∑–∞–¥']
    }
    
    def __init__(self):
        super().__init__('voice_controller')
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ —Ä–µ—Å—É—Ä—Å–∞–º –ø–∞–∫–µ—Ç–∞
        package_share_path = get_package_share_directory('voice_controlled_robot')
        self.resources_path = os.path.join(package_share_path, 'resources')
        
        # –î–æ–±–∞–≤–ª—è–µ–º URBasic –≤ –ø—É—Ç—å Python
        urbasic_path = os.path.join(self.resources_path, 'URBasic')
        if urbasic_path not in sys.path:
            sys.path.insert(0, urbasic_path)
        
        print(f"üîß –†–µ—Å—É—Ä—Å—ã –ø–∞–∫–µ—Ç–∞: {self.resources_path}")
        print(f"üîß –ü—É—Ç—å URBasic: {urbasic_path}")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
        self.robot = None
        self.robot_model = None
        self.audio_queue = queue.Queue()
        self.sample_rate = None
        self.audio_device = None
        self.recognizer = None
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        self.declare_parameters(
            namespace='',
            parameters=[
                ('robot_host', '192.168.0.100'),
                ('waiting_pose', [-0.19, -0.315, 0.350, 2.783, -1.353, 0.03]),
                ('dog_pose', [-0.828, -0.624, 0.490, 2.003, -1.873, 0.08]),
                ('looking_poses', [
                    [-0.22, -0.873, 1, 1.539, -0.749, 0.584],
                    [0.185, -0.893, 1.1, 1.614, -0.831, 0.133],
                    [-0.610, -0.650, 0.890, 1.607, -0.822, 0.750],
                    [-0.228, -0.388, 1.26, 1.435, -0.730, 0.592],
                    [-0.22, -0.873, 1, 1.539, -0.749, 0.584]
                ]),
                ('sample_rate', 16000),
                ('similarity_threshold', 0.7),
                ('position_timeout', 15.0),
                ('pause_duration', 2.0)
            ]
        )
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        self.robot_host = self.get_parameter('robot_host').value
        self.waiting_pose = self.get_parameter('waiting_pose').value
        self.dog_pose = self.get_parameter('dog_pose').value
        self.looking_poses = self.get_parameter('looking_poses').value
        self.sample_rate = self.get_parameter('sample_rate').value
        self.similarity_threshold = self.get_parameter('similarity_threshold').value
        self.position_timeout = self.get_parameter('position_timeout').value
        self.pause_duration = self.get_parameter('pause_duration').value
        
        self.get_logger().info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Voice Controller...")

    @staticmethod
    def normalize_angle(angle):
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —É–≥–æ–ª –≤ –¥–∏–∞–ø–∞–∑–æ–Ω [-pi, pi]."""
        while angle > math.pi:
            angle -= 2 * math.pi
        while angle < -math.pi:
            angle += 2 * math.pi
        return angle

    def check_position(self, current_pos, target_pos, linear_tolerance=0.001, angle_tolerance=0.01):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ –ª–∏ —Ü–µ–ª–µ–≤–∞—è –ø–æ–∑–∏—Ü–∏—è."""
        position_reached = True
        
        self.get_logger().debug("–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–∑–∏—Ü–∏–∏:")
        for i, (current, target) in enumerate(zip(current_pos, target_pos)):
            if i < 3:  # –ü–æ–∑–∏—Ü–∏—è (x, y, z)
                diff = abs(current - target)
                if diff > linear_tolerance:
                    position_reached = False
                status = '‚úì' if diff <= linear_tolerance else '‚úó'
                self.get_logger().debug(
                    f"–û—Å—å {i}(–ª–∏–Ω.): —Ç–µ–∫—É—â–∞—è={current:08.6f}, "
                    f"—Ü–µ–ª–µ–≤–∞—è={target:08.6f}, —Ä–∞–∑–Ω–∏—Ü–∞={diff:08.6f} {status}"
                )
            else:  # –û—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è (rx, ry, rz)
                norm_current = self.normalize_angle(current)
                norm_target = self.normalize_angle(target)
                diff = abs(-norm_current - norm_target)
                if diff > angle_tolerance:
                    position_reached = False
                status = '‚úì' if diff <= angle_tolerance else '‚úó'
                self.get_logger().debug(
                    f"–û—Å—å {i}(—É–≥–ª.): —Ç–µ–∫—É—â–∞—è={current:08.6f}‚Üí{norm_current:08.6f}, "
                    f"—Ü–µ–ª–µ–≤–∞—è={target:08.6f}‚Üí{norm_target:08.6f}, "
                    f"—Ä–∞–∑–Ω–∏—Ü–∞={diff:08.6f} {status}"
                )
        
        self.get_logger().debug(f"–ü–æ–∑–∏—Ü–∏—è –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞: {position_reached}")
        return position_reached

    def wait_for_position(self, target_pos, position_name="", timeout=15.0, check_interval=0.05):
        """–û–∂–∏–¥–∞–µ—Ç –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–π –ø–æ–∑–∏—Ü–∏–∏ —Å —Ç–∞–π–º–∞—É—Ç–æ–º."""
        start_time = time.time()
        attempt = 0
        
        while time.time() - start_time < timeout:
            attempt += 1
            current_pos = self.robot.get_actual_tcp_pose_custom()
            
            if self.check_position(current_pos, target_pos):
                self.get_logger().info(f"‚úì –ü–æ–∑–∏—Ü–∏—è '{position_name}' —É—Å–ø–µ—à–Ω–æ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞!")
                return True
            
            if attempt % 10 == 0:
                elapsed = time.time() - start_time
                self.get_logger().info(f"–ü—Ä–æ–≥—Ä–µ—Å—Å: {elapsed:.1f}—Å –∏–∑ {timeout}—Å")
            
            time.sleep(check_interval)
        
        self.get_logger().error(f"‚úó –¢–∞–π–º–∞—É—Ç: –ø–æ–∑–∏—Ü–∏—è '{position_name}' –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ –∑–∞ {timeout} —Å–µ–∫—É–Ω–¥")
        return False

    def initialize_robot(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å —Ä–æ–±–æ—Ç–æ–º."""
        self.get_logger().info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è UR —Ä–æ–±–æ—Ç–∞")
        self.robot_model = URBasic.robotModel.RobotModel()
        self.robot = URBasic.urScriptExt.UrScriptExt(
            host=self.robot_host, 
            robotModel=self.robot_model
        )
        self.robot.init_realtime_control()
        
        current_pos = self.robot.get_actual_tcp_pose_custom()
        self.get_logger().info(
            f'–¢–µ–∫—É—â–∞—è –ø–æ–∑–∏—Ü–∏—è —Ä–æ–±–æ—Ç–∞: '
            f'[{current_pos[0]:08.6f}, {current_pos[1]:08.6f}, {current_pos[2]:08.6f}, '
            f'{current_pos[3]:08.6f}, {current_pos[4]:08.6f}, {current_pos[5]:08.6f}]'
        )
        
        return self.robot

    def move_to_position(self, target_pos, position_name):
        """–ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ —Ä–æ–±–æ—Ç–∞ –≤ —É–∫–∞–∑–∞–Ω–Ω—É—é –ø–æ–∑–∏—Ü–∏—é."""
        self.get_logger().info(f"–ü–µ—Ä–µ—Ö–æ–¥ –≤ –ø–æ–∑–∏—Ü–∏—é '{position_name}': {target_pos}")
        self.robot.set_realtime_pose(target_pos)
        
        if not self.wait_for_position(target_pos, position_name, self.position_timeout):
            self.get_logger().error(f"–û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –¥–æ—Å—Ç–∏—á—å –ø–æ–∑–∏—Ü–∏–∏ '{position_name}'")
            return False
        return True

    @staticmethod
    def pause_at_position(position_name, duration=2.0):
        """–ü–∞—É–∑–∞ –≤ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–æ–π –ø–æ–∑–∏—Ü–∏–∏."""
        print(f"‚è∏Ô∏è  –ü–∞—É–∑–∞ {duration} —Å–µ–∫—É–Ω–¥ –≤ –ø–æ–∑–∏—Ü–∏–∏ '{position_name}'...")
        time.sleep(duration)
        print(f"‚ñ∂Ô∏è  –ü–∞—É–∑–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É.")

    @staticmethod
    def similarity(a, b):
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç—å –¥–≤—É—Ö —Å—Ç—Ä–æ–∫."""
        return SequenceMatcher(None, a, b).ratio()

    def find_tools_in_command(self, command, similarity_threshold=0.7):
        """–ü–æ–∏—Å–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –≤ –≥–æ–ª–æ—Å–æ–≤–æ–π –∫–æ–º–∞–Ω–¥–µ."""
        command = command.lower().strip()
        found_tools = []
        
        # –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –ø–æ –ø–æ–¥—Å—Ç—Ä–æ–∫–µ
        for tool, keywords in self.TOOLS_DICT.items():
            for keyword in keywords:
                if keyword in command:
                    found_tools.append(tool)
                    break
        
        if found_tools:
            return list(set(found_tools))
        
        # –ü–æ–∏—Å–∫ –ø–æ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è —Å–ª—É—á–∞–µ–≤ —Å –æ—à–∏–±–∫–∞–º–∏
        words = re.findall(r'\w+', command)
        for word in words:
            for tool, keywords in self.TOOLS_DICT.items():
                for keyword in keywords:
                    if self.similarity(word, keyword) >= similarity_threshold:
                        found_tools.append(tool)
                        break
        
        return list(set(found_tools))

    def pick_input_device(self):
        """–í—ã–±–æ—Ä –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –¥–ª—è –∑–∞–ø–∏—Å–∏."""
        devices = sd.query_devices()
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: pulse ‚Üí default ‚Üí –ª—é–±–æ–π —Å –≤—Ö–æ–¥–æ–º
        for i, device in enumerate(devices):
            if (device["max_input_channels"] > 0 and 
                device["name"].lower() == "pulse"):
                self.get_logger().info(f"–í—ã–±—Ä–∞–Ω–æ –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device['name']}")
                return i
                
        for i, device in enumerate(devices):
            if (device["max_input_channels"] > 0 and 
                device["name"].lower() == "default"):
                self.get_logger().info(f"–í—ã–±—Ä–∞–Ω–æ –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device['name']}")
                return i
                
        for i, device in enumerate(devices):
            if (device["max_input_channels"] > 0 and 
                "hdmi" not in device["name"].lower()):
                self.get_logger().info(f"–í—ã–±—Ä–∞–Ω–æ –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device['name']}")
                return i
                
        raise RuntimeError("–ù–µ—Ç –≤—Ö–æ–¥–Ω—ã—Ö –∞—É–¥–∏–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤")

    def audio_callback(self, indata, frames, time_info, status):
        """Callback —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫–∞."""
        if status:
            self.get_logger().warn(f"–ê—É–¥–∏–æ —Å—Ç–∞—Ç—É—Å: {status}")
        self.audio_queue.put(bytes(indata))

    def initialize_audio(self, model_path):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ —Å–∏—Å—Ç–µ–º—ã."""
        self.audio_device = self.pick_input_device()
        
        model = vosk.Model(model_path)
        self.recognizer = vosk.KaldiRecognizer(model, self.sample_rate)
        
        return sd.RawInputStream(
            callback=self.audio_callback,
            channels=1,
            samplerate=self.sample_rate,
            device=self.audio_device,
            dtype='int16'
        )

    def execute_command(self, tools):
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤."""
        if not tools:
            return
            
        action = tools[0]
        
        if action == '—Å–æ–±–∞—á–∫–∞':
            self.move_to_position(self.dog_pose, "–ü–æ–∑–∏—Ü–∏—è —Å–æ–±–∞—á–∫–∏")
            self.pause_at_position("–ü–æ–∑–∏—Ü–∏—è —Å–æ–±–∞—á–∫–∏", self.pause_duration)
            
        elif action == '–Ω–∞–∑–∞–¥':
            self.move_to_position(self.waiting_pose, "–ù–∞—á–∞–ª—å–Ω–∞—è –ø–æ–∑–∏—Ü–∏—è")
            
        elif action == '–ø–æ—Å–º–æ—Ç—Ä–∏':
            for i, pose in enumerate(self.looking_poses):
                self.move_to_position(pose, f"–ü–æ–∑–∏—Ü–∏—è –æ—Å–º–æ—Ç—Ä–∞ {i+1}")
                self.pause_at_position(f"–ü–æ–∑–∏—Ü–∏—è –æ—Å–º–æ—Ç—Ä–∞ {i+1}", 1.0)

    def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Ä–∞–±–æ—Ç—ã —É–∑–ª–∞."""
        try:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–æ–±–æ—Ç–∞
            self.initialize_robot()
            
            # –ü–µ—Ä–µ—Ö–æ–¥ –≤ –Ω–∞—á–∞–ª—å–Ω—É—é –ø–æ–∑–∏—Ü–∏—é
            self.get_logger().info("–ü–µ—Ä–µ—Ö–æ–¥ –≤ –Ω–∞—á–∞–ª—å–Ω—É—é –ø–æ–∑–∏—Ü–∏—é...")
            if not self.move_to_position(self.waiting_pose, "–ù–∞—á–∞–ª—å–Ω–∞—è –ø–æ–∑–∏—Ü–∏—è"):
                return
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ
            model_path = os.path.join(
                get_package_share_directory('voice_controlled_robot'),
                'resources',
                'vosk-model-small-ru-0.22'
            )
            
            # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ resources, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—É—é
            if not os.path.exists(model_path):
                model_path = "model_stt/vosk-model-small-ru-0.22"
                self.get_logger().warn(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –ø–∞–∫–µ—Ç–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—É—é: {model_path}")
            
            with self.initialize_audio(model_path) as stream:
                self.get_logger().info("üé§ –ì–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∑–∞–ø—É—â–µ–Ω. –ì–æ–≤–æ—Ä–∏—Ç–µ...")
                
                while rclpy.ok():
                    data = self.audio_queue.get()
                    if self.recognizer.AcceptWaveform(data):
                        result = json.loads(self.recognizer.Result())
                        text = result.get("text", "").strip()
                        
                        if text:
                            self.get_logger().info(f"üó£Ô∏è –ö–æ–º–∞–Ω–¥–∞: {text}")
                            
                            tools = self.find_tools_in_command(text, self.similarity_threshold)
                            
                            if tools:
                                self.get_logger().info(f"üéØ –†–∞—Å–ø–æ–∑–Ω–∞–Ω—ã –¥–µ–π—Å—Ç–≤–∏—è: {', '.join(tools)}")
                                self.execute_command(tools)
                            else:
                                self.get_logger().warn("‚ùå –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω—ã")
                                
                    else:
                        partial_result = json.loads(self.recognizer.PartialResult())
                        partial_text = partial_result.get("partial", "").strip()
                        if partial_text:
                            print(f"‚ñå –°–ª—É—à–∞—é: {partial_text}", end='\r')
                            
        except KeyboardInterrupt:
            self.get_logger().info("‚úÖ –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        except Exception as e:
            self.get_logger().error(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        finally:
            if self.robot:
                self.robot.close()

def main(args=None):
    rclpy.init(args=args)
    
    voice_controller = VoiceController()
    
    try:
        voice_controller.run()
    except Exception as e:
        voice_controller.get_logger().error(f"–û—à–∏–±–∫–∞ –≤ main: {e}")
    finally:
        voice_controller.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()
